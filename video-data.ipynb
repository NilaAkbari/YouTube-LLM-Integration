{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import polars as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from os import getenv\n",
    "import dotenv\n",
    "from flask import Flask\n",
    "dotenv.load_dotenv()\n",
    "YOUTUBE_API_KEY = getenv(\"YOUTUBE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding\\YouTube-LLM-Integration\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics import DistanceMetric\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getVideoRecords(response: requests.models.Response) -> list:\n",
    "    \"\"\"\n",
    "        Function to extract YouTube video data from GET request response\n",
    "    \"\"\"\n",
    "\n",
    "    video_record_list = []\n",
    "    \n",
    "    for raw_item in json.loads(response.text)['items']:\n",
    "    \n",
    "        # only execute for youtube videos\n",
    "        if raw_item['id']['kind'] != \"youtube#video\":\n",
    "            continue\n",
    "        \n",
    "        video_record = {}\n",
    "        video_record['video_id'] = raw_item['id']['videoId']\n",
    "        video_record['datetime'] = raw_item['snippet']['publishedAt']\n",
    "        video_record['title'] = raw_item['snippet']['title']\n",
    "        \n",
    "        video_record_list.append(video_record)\n",
    "\n",
    "    return video_record_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(transcript: list) -> str:\n",
    "    \"\"\"\n",
    "        Function to extract text from transcript dictionary\n",
    "    \"\"\"\n",
    "    \n",
    "    text_list = [transcript[i]['text'] for i in range(len(transcript))]\n",
    "    return ' '.join(text_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define channel ID\n",
    "channel_id = 'UCsXVk37bltHxD1rDPwtNM8Q'\n",
    "\n",
    "# define url for API\n",
    "url = 'https://www.googleapis.com/youtube/v3/search'\n",
    "\n",
    "# initialize page token\n",
    "page_token = None\n",
    "\n",
    "# intialize list to store video data\n",
    "video_record_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# extract video data across multiple search result pages\n",
    "while page_token != 0:\n",
    "    # define parameters for API call\n",
    "    params = {\n",
    "        \"key\": YOUTUBE_API_KEY, \n",
    "        'channelId': channel_id, \n",
    "        'part': [\"snippet\",\"id\"], \n",
    "        'maxResults':50, \n",
    "        'order': 'date',\n",
    "        'pageToken': page_token\n",
    "    }\n",
    "    # make get request\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    # check for errors\n",
    "    if response.status_code != 200:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "        print(\"were here\")\n",
    "        break\n",
    "\n",
    "\n",
    "    # append video records to list\n",
    "    video_record_list += getVideoRecords(response)\n",
    "\n",
    "    try:\n",
    "        # grab next page token\n",
    "        page_token = json.loads(response.text)['nextPageToken']\n",
    "    except:\n",
    "        # if no next page token kill while loop\n",
    "        page_token = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write data to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to file\n",
    "pl.DataFrame(video_record_list).write_parquet('data/video-ids.parquet')\n",
    "pl.DataFrame(video_record_list).write_csv('data/video-ids.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get Transcripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 3)\n",
      "┌─────────────┬──────────────────────┬─────────────────────────────────┐\n",
      "│ video_id    ┆ datetime             ┆ title                           │\n",
      "│ ---         ┆ ---                  ┆ ---                             │\n",
      "│ str         ┆ str                  ┆ str                             │\n",
      "╞═════════════╪══════════════════════╪═════════════════════════════════╡\n",
      "│ dIpttD7b8B4 ┆ 2024-09-12T14:00:39Z ┆ Why Do Puddles Disappear but L… │\n",
      "│ vSSkDos2hzo ┆ 2024-09-12T14:01:11Z ┆ We Need to Rethink Exercise (U… │\n",
      "│ _kelDJFjhOo ┆ 2024-09-05T14:00:37Z ┆ The Perfect Sofa – According t… │\n",
      "│ 49ApsH6lzk0 ┆ 2024-08-29T14:00:05Z ┆ This Happens When You Get a Ta… │\n",
      "│ dBxxi5XAm3U ┆ 2024-08-27T14:00:00Z ┆ We Traveled Back in Time. Now … │\n",
      "└─────────────┴──────────────────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "df = pl.read_parquet('data/video-ids.parquet')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 5.72 s\n",
      "Wall time: 4min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "transcript_text_list = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "\n",
    "    # try to extract captions\n",
    "    try:\n",
    "        transcript = YouTubeTranscriptApi.get_transcript(df['video_id'][i])\n",
    "        transcript_text = extract_text(transcript)\n",
    "    # if not available set as n/a\n",
    "    except:\n",
    "        transcript_text = \"n/a\"\n",
    "    \n",
    "    transcript_text_list.append(transcript_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────────┬──────────────────────┬──────────────────────────────┬──────────────────────────────┐\n",
      "│ video_id    ┆ datetime             ┆ title                        ┆ transcript                   │\n",
      "│ ---         ┆ ---                  ┆ ---                          ┆ ---                          │\n",
      "│ str         ┆ str                  ┆ str                          ┆ str                          │\n",
      "╞═════════════╪══════════════════════╪══════════════════════════════╪══════════════════════════════╡\n",
      "│ dIpttD7b8B4 ┆ 2024-09-12T14:00:39Z ┆ Why Do Puddles Disappear but ┆ n/a                          │\n",
      "│             ┆                      ┆ L…                           ┆                              │\n",
      "│ vSSkDos2hzo ┆ 2024-09-12T14:01:11Z ┆ We Need to Rethink Exercise  ┆ Losing weight is hard and    │\n",
      "│             ┆                      ┆ (U…                          ┆ unfo…                        │\n",
      "│ _kelDJFjhOo ┆ 2024-09-05T14:00:37Z ┆ The Perfect Sofa – According ┆ n/a                          │\n",
      "│             ┆                      ┆ t…                           ┆                              │\n",
      "│ 49ApsH6lzk0 ┆ 2024-08-29T14:00:05Z ┆ This Happens When You Get a  ┆ your tattoos are inside your │\n",
      "│             ┆                      ┆ Ta…                          ┆ i…                           │\n",
      "│ dBxxi5XAm3U ┆ 2024-08-27T14:00:00Z ┆ We Traveled Back in Time.    ┆ You’re going forward through │\n",
      "│             ┆                      ┆ Now …                        ┆ t…                           │\n",
      "└─────────────┴──────────────────────┴──────────────────────────────┴──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# add transcripts to dataframe\n",
    "df = df.with_columns(pl.Series(name=\"transcript\", values=transcript_text_list))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (244, 4)\n",
      "n unique rows: 242\n",
      "n unique elements (video_id): 242\n",
      "n unique elements (datetime): 242\n",
      "n unique elements (title): 242\n",
      "n unique elements (transcript): 216\n"
     ]
    }
   ],
   "source": [
    "# shape + unique values\n",
    "print(\"shape:\", df.shape)\n",
    "print(\"n unique rows:\", df.n_unique())\n",
    "for j in range(df.shape[1]):\n",
    "    print(\"n unique elements (\" + df.columns[j] + \"):\", df[:,j].n_unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.filter(~pl.col('title').str.contains(\"#shorts\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (199, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>video_id</th><th>datetime</th><th>title</th><th>transcript</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;vSSkDos2hzo&quot;</td><td>&quot;2024-09-12T14:01:11Z&quot;</td><td>&quot;We Need to Rethink Exercise (U…</td><td>&quot;Losing weight is hard and unfo…</td></tr><tr><td>&quot;dBxxi5XAm3U&quot;</td><td>&quot;2024-08-27T14:00:00Z&quot;</td><td>&quot;We Traveled Back in Time. Now …</td><td>&quot;You’re going forward through t…</td></tr><tr><td>&quot;cRZOUcpiOxY&quot;</td><td>&quot;2024-08-13T14:00:01Z&quot;</td><td>&quot;Fever Feels Horrible, but is A…</td><td>&quot;Fever feels bad. So we take me…</td></tr><tr><td>&quot;fa8k8IQ1_X0&quot;</td><td>&quot;2024-08-06T14:00:09Z&quot;</td><td>&quot;A.I. ‐ Humanity&amp;#39;s Final In…</td><td>&quot;humans rule Earth without comp…</td></tr><tr><td>&quot;GFLb5h2O2Ww&quot;</td><td>&quot;2024-06-25T14:00:01Z&quot;</td><td>&quot;This Disease is Deadlier Than …</td><td>&quot;Hello, Steve here. Today I am …</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;F3QpgXBtDeo&quot;</td><td>&quot;2013-11-28T17:03:32Z&quot;</td><td>&quot;How The Stock Exchange Works (…</td><td>&quot;What is the Stock Exchange \n",
       "an…</td></tr><tr><td>&quot;UuGrBhK2c7U&quot;</td><td>&quot;2013-10-11T19:11:39Z&quot;</td><td>&quot;The Gulf Stream Explained&quot;</td><td>&quot;The ocean conveyor belt and\n",
       "th…</td></tr><tr><td>&quot;Uti2niW2BRA&quot;</td><td>&quot;2013-09-03T09:12:24Z&quot;</td><td>&quot;Fracking explained: opportunit…</td><td>&quot;What is hydraulic fracturing –…</td></tr><tr><td>&quot;KsF_hdjWJjo&quot;</td><td>&quot;2013-08-22T13:24:56Z&quot;</td><td>&quot;The Solar System -- our home i…</td><td>&quot;the solar system our home in s…</td></tr><tr><td>&quot;hOfRN0KihOU&quot;</td><td>&quot;2013-07-11T14:09:52Z&quot;</td><td>&quot;How Evolution works&quot;</td><td>&quot;Mechanisms of evolution What i…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (199, 4)\n",
       "┌─────────────┬──────────────────────┬──────────────────────────────┬──────────────────────────────┐\n",
       "│ video_id    ┆ datetime             ┆ title                        ┆ transcript                   │\n",
       "│ ---         ┆ ---                  ┆ ---                          ┆ ---                          │\n",
       "│ str         ┆ str                  ┆ str                          ┆ str                          │\n",
       "╞═════════════╪══════════════════════╪══════════════════════════════╪══════════════════════════════╡\n",
       "│ vSSkDos2hzo ┆ 2024-09-12T14:01:11Z ┆ We Need to Rethink Exercise  ┆ Losing weight is hard and    │\n",
       "│             ┆                      ┆ (U…                          ┆ unfo…                        │\n",
       "│ dBxxi5XAm3U ┆ 2024-08-27T14:00:00Z ┆ We Traveled Back in Time.    ┆ You’re going forward through │\n",
       "│             ┆                      ┆ Now …                        ┆ t…                           │\n",
       "│ cRZOUcpiOxY ┆ 2024-08-13T14:00:01Z ┆ Fever Feels Horrible, but is ┆ Fever feels bad. So we take  │\n",
       "│             ┆                      ┆ A…                           ┆ me…                          │\n",
       "│ fa8k8IQ1_X0 ┆ 2024-08-06T14:00:09Z ┆ A.I. ‐ Humanity&#39;s Final  ┆ humans rule Earth without    │\n",
       "│             ┆                      ┆ In…                          ┆ comp…                        │\n",
       "│ GFLb5h2O2Ww ┆ 2024-06-25T14:00:01Z ┆ This Disease is Deadlier     ┆ Hello, Steve here. Today I   │\n",
       "│             ┆                      ┆ Than …                       ┆ am …                         │\n",
       "│ …           ┆ …                    ┆ …                            ┆ …                            │\n",
       "│ F3QpgXBtDeo ┆ 2013-11-28T17:03:32Z ┆ How The Stock Exchange Works ┆ What is the Stock Exchange   │\n",
       "│             ┆                      ┆ (…                           ┆ an…                          │\n",
       "│ UuGrBhK2c7U ┆ 2013-10-11T19:11:39Z ┆ The Gulf Stream Explained    ┆ The ocean conveyor belt and  │\n",
       "│             ┆                      ┆                              ┆ th…                          │\n",
       "│ Uti2niW2BRA ┆ 2013-09-03T09:12:24Z ┆ Fracking explained:          ┆ What is hydraulic fracturing │\n",
       "│             ┆                      ┆ opportunit…                  ┆ –…                           │\n",
       "│ KsF_hdjWJjo ┆ 2013-08-22T13:24:56Z ┆ The Solar System -- our home ┆ the solar system our home in │\n",
       "│             ┆                      ┆ i…                           ┆ s…                           │\n",
       "│ hOfRN0KihOU ┆ 2013-07-11T14:09:52Z ┆ How Evolution works          ┆ Mechanisms of evolution What │\n",
       "│             ┆                      ┆                              ┆ i…                           │\n",
       "└─────────────┴──────────────────────┴──────────────────────────────┴──────────────────────────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (199, 4)\n",
      "n unique rows: 197\n",
      "n unique elements (video_id): 197\n",
      "n unique elements (datetime): 197\n",
      "n unique elements (title): 197\n",
      "n unique elements (transcript): 197\n"
     ]
    }
   ],
   "source": [
    "# shape + unique values\n",
    "print(\"shape:\", filtered_df.shape)\n",
    "print(\"n unique rows:\", filtered_df.n_unique())\n",
    "for j in range(filtered_df.shape[1]):\n",
    "    print(\"n unique elements (\" + filtered_df.columns[j] + \"):\", filtered_df[:,j].n_unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (0, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>video_id</th><th>datetime</th><th>title</th><th>transcript</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (0, 4)\n",
       "┌──────────┬──────────┬───────┬────────────┐\n",
       "│ video_id ┆ datetime ┆ title ┆ transcript │\n",
       "│ ---      ┆ ---      ┆ ---   ┆ ---        │\n",
       "│ str      ┆ str      ┆ str   ┆ str        │\n",
       "╞══════════╪══════════╪═══════╪════════════╡\n",
       "└──────────┴──────────┴───────┴────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.filter(pl.col(\"transcript\") == \"n/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write data to file\n",
    "filtered_df.write_parquet('data/video-transcripts.parquet')\n",
    "filtered_df.write_csv('data/video-transcripts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# validate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet('data/video-transcripts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────────┬─────────────────────┬───────────────────────────────┬──────────────────────────────┐\n",
      "│ video_id    ┆ datetime            ┆ title                         ┆ transcript                   │\n",
      "│ ---         ┆ ---                 ┆ ---                           ┆ ---                          │\n",
      "│ str         ┆ datetime[μs]        ┆ str                           ┆ str                          │\n",
      "╞═════════════╪═════════════════════╪═══════════════════════════════╪══════════════════════════════╡\n",
      "│ vSSkDos2hzo ┆ 2024-09-12 14:01:11 ┆ We Need to Rethink Exercise   ┆ Losing weight is hard and    │\n",
      "│             ┆                     ┆ (U…                           ┆ unfo…                        │\n",
      "│ dBxxi5XAm3U ┆ 2024-08-27 14:00:00 ┆ We Traveled Back in Time. Now ┆ You’re going forward through │\n",
      "│             ┆                     ┆ …                             ┆ t…                           │\n",
      "│ cRZOUcpiOxY ┆ 2024-08-13 14:00:01 ┆ Fever Feels Horrible, but is  ┆ Fever feels bad. So we take  │\n",
      "│             ┆                     ┆ A…                            ┆ me…                          │\n",
      "│ fa8k8IQ1_X0 ┆ 2024-08-06 14:00:09 ┆ A.I. ‐ Humanity&#39;s Final   ┆ humans rule Earth without    │\n",
      "│             ┆                     ┆ In…                           ┆ comp…                        │\n",
      "│ GFLb5h2O2Ww ┆ 2024-06-25 14:00:01 ┆ This Disease is Deadlier Than ┆ Hello, Steve here. Today I   │\n",
      "│             ┆                     ┆ …                             ┆ am …                         │\n",
      "└─────────────┴─────────────────────┴───────────────────────────────┴──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "# change datetime to Datetime dtype\n",
    "df = df.with_columns(pl.col('datetime').cast(pl.Datetime))\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "special_strings = ['&#39;', '&amp;']\n",
    "special_string_replacements = [\"'\", \"&\"]\n",
    "\n",
    "for i in range(len(special_strings)):\n",
    "    df = df.with_columns(df['title'].str.replace(special_strings[i], special_string_replacements[i]).alias('title'))\n",
    "    df = df.with_columns(df['transcript'].str.replace(special_strings[i], special_string_replacements[i]).alias('transcript'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_parquet('data/video-transcripts.parquet')\n",
    "df.write_csv('data/video-transcripts.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pl.read_parquet('data/video-transcripts.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 4)\n",
      "┌─────────────┬─────────────────────┬───────────────────────────────┬──────────────────────────────┐\n",
      "│ video_id    ┆ datetime            ┆ title                         ┆ transcript                   │\n",
      "│ ---         ┆ ---                 ┆ ---                           ┆ ---                          │\n",
      "│ str         ┆ datetime[μs]        ┆ str                           ┆ str                          │\n",
      "╞═════════════╪═════════════════════╪═══════════════════════════════╪══════════════════════════════╡\n",
      "│ vSSkDos2hzo ┆ 2024-09-12 14:01:11 ┆ We Need to Rethink Exercise   ┆ Losing weight is hard and    │\n",
      "│             ┆                     ┆ (Upd…                         ┆ unfort…                      │\n",
      "│ dBxxi5XAm3U ┆ 2024-08-27 14:00:00 ┆ We Traveled Back in Time. Now ┆ You’re going forward through │\n",
      "│             ┆                     ┆ Ph…                           ┆ tim…                         │\n",
      "│ cRZOUcpiOxY ┆ 2024-08-13 14:00:01 ┆ Fever Feels Horrible, but is  ┆ Fever feels bad. So we take  │\n",
      "│             ┆                     ┆ Act…                          ┆ medi…                        │\n",
      "│ fa8k8IQ1_X0 ┆ 2024-08-06 14:00:09 ┆ A.I. ‐ Humanity's Final       ┆ humans rule Earth without    │\n",
      "│             ┆                     ┆ Inventio…                     ┆ compet…                      │\n",
      "│ GFLb5h2O2Ww ┆ 2024-06-25 14:00:01 ┆ This Disease is Deadlier Than ┆ Hello, Steve here. Today I   │\n",
      "│             ┆                     ┆ Th…                           ┆ am mo…                       │\n",
      "└─────────────┴─────────────────────┴───────────────────────────────┴──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 203 ms\n",
      "Wall time: 4.06 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\coding\\YouTube-LLM-Integration\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model_name = 'all-MiniLM-L6-v2'\n",
    "%time model = SentenceTransformer(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>video_id</th><th>datetime</th><th>title</th><th>transcript</th></tr><tr><td>str</td><td>datetime[μs]</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;vSSkDos2hzo&quot;</td><td>2024-09-12 14:01:11</td><td>&quot;We Need to Ret…</td><td>&quot;Losing weight …</td></tr><tr><td>&quot;dBxxi5XAm3U&quot;</td><td>2024-08-27 14:00:00</td><td>&quot;We Traveled Ba…</td><td>&quot;You’re going f…</td></tr><tr><td>&quot;cRZOUcpiOxY&quot;</td><td>2024-08-13 14:00:01</td><td>&quot;Fever Feels Ho…</td><td>&quot;Fever feels ba…</td></tr><tr><td>&quot;fa8k8IQ1_X0&quot;</td><td>2024-08-06 14:00:09</td><td>&quot;A.I. ‐ Humanit…</td><td>&quot;humans rule Ea…</td></tr><tr><td>&quot;GFLb5h2O2Ww&quot;</td><td>2024-06-25 14:00:01</td><td>&quot;This Disease i…</td><td>&quot;Hello, Steve h…</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 4)\n",
       "┌─────────────┬─────────────────────┬───────────────────────────────┬──────────────────────────────┐\n",
       "│ video_id    ┆ datetime            ┆ title                         ┆ transcript                   │\n",
       "│ ---         ┆ ---                 ┆ ---                           ┆ ---                          │\n",
       "│ str         ┆ datetime[μs]        ┆ str                           ┆ str                          │\n",
       "╞═════════════╪═════════════════════╪═══════════════════════════════╪══════════════════════════════╡\n",
       "│ vSSkDos2hzo ┆ 2024-09-12 14:01:11 ┆ We Need to Rethink Exercise   ┆ Losing weight is hard and    │\n",
       "│             ┆                     ┆ (Upd…                         ┆ unfort…                      │\n",
       "│ dBxxi5XAm3U ┆ 2024-08-27 14:00:00 ┆ We Traveled Back in Time. Now ┆ You’re going forward through │\n",
       "│             ┆                     ┆ Ph…                           ┆ tim…                         │\n",
       "│ cRZOUcpiOxY ┆ 2024-08-13 14:00:01 ┆ Fever Feels Horrible, but is  ┆ Fever feels bad. So we take  │\n",
       "│             ┆                     ┆ Act…                          ┆ medi…                        │\n",
       "│ fa8k8IQ1_X0 ┆ 2024-08-06 14:00:09 ┆ A.I. ‐ Humanity's Final       ┆ humans rule Earth without    │\n",
       "│             ┆                     ┆ Inventio…                     ┆ compet…                      │\n",
       "│ GFLb5h2O2Ww ┆ 2024-06-25 14:00:01 ┆ This Disease is Deadlier Than ┆ Hello, Steve here. Today I   │\n",
       "│             ┆                     ┆ Th…                           ┆ am mo…                       │\n",
       "└─────────────┴─────────────────────┴───────────────────────────────┴──────────────────────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pl.read_parquet('data/video-transcripts.parquet')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_name_list = ['title', 'transcript']\n",
    "\n",
    "for column_name in column_name_list:\n",
    "    # generate embeddings\n",
    "    embedding_arr = model.encode(df[column_name].to_list())\n",
    "\n",
    "    # store embeddings in a dataframe\n",
    "    schema_dict = {column_name+'_embedding-'+str(i): float for i in range(embedding_arr.shape[1])}\n",
    "    df_embedding = pl.DataFrame(embedding_arr, schema=schema_dict)\n",
    "\n",
    "    # append embeddings to video index\n",
    "    df = pl.concat([df, df_embedding], how='horizontal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write_parquet('data/video-index.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time df = pl.scan_parquet('data/video-index.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "dist_name = 'manhattan'\n",
    "%time dist = DistanceMetric.get_metric(dist_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnSearchResults(query: str, index: pl.lazyframe.frame.LazyFrame) -> np.ndarray:\n",
    "    \"\"\"\n",
    "        Function to return indexes of top search results\n",
    "    \"\"\"\n",
    "    \n",
    "    # embed query\n",
    "    query_embedding = model.encode(query).reshape(1, -1)\n",
    "    \n",
    "    # compute distances between query and titles/transcripts\n",
    "    dist_arr = dist.pairwise(df.select(df.columns[4:388]).collect(), query_embedding) + dist.pairwise(df.select(df.columns[388:]).collect(), query_embedding)\n",
    "\n",
    "    # search paramaters\n",
    "    threshold = 40 # eye balled threshold for manhatten distance\n",
    "    top_k = 5\n",
    "\n",
    "    # evaluate videos close to query based on threshold\n",
    "    idx_below_threshold = np.argwhere(dist_arr.flatten()<threshold).flatten()\n",
    "    # keep top k closest videos\n",
    "    idx_sorted = np.argsort(dist_arr[idx_below_threshold], axis=0).flatten()\n",
    "\n",
    "    # return indexes of search results\n",
    "    return idx_below_threshold[idx_sorted][:top_k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (5, 2)\n",
      "┌─────────────┬───────────────────────────────────┐\n",
      "│ video_id    ┆ title                             │\n",
      "│ ---         ┆ ---                               │\n",
      "│ str         ┆ str                               │\n",
      "╞═════════════╪═══════════════════════════════════╡\n",
      "│ dBxxi5XAm3U ┆ We Traveled Back in Time. Now Ph… │\n",
      "│ wwSzpaTHyS8 ┆ Did The Future Already Happen? -… │\n",
      "│ 2XkV6IpV2Y0 ┆ The History and Future of Everyt… │\n",
      "│ CWu29PRCUvQ ┆ When Time Became History - The H… │\n",
      "│ 5TbUxGZtwGI ┆ Time: The History & Future of Ev… │\n",
      "└─────────────┴───────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "query = \"Time Travel\"\n",
    "idx_result = returnSearchResults(query, df)\n",
    "\n",
    "print(df.select(['video_id', 'title']).collect()[idx_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': ['We Traveled Back in Time. Now Physicists Are Angry.',\n",
       "  'Did The Future Already Happen? - The Paradox of Time',\n",
       "  'The History and Future of Everything -- Time',\n",
       "  'When Time Became History - The Human Era',\n",
       "  'Time: The History & Future of Everything – Remastered'],\n",
       " 'video_id': ['dBxxi5XAm3U',\n",
       "  'wwSzpaTHyS8',\n",
       "  '2XkV6IpV2Y0',\n",
       "  'CWu29PRCUvQ',\n",
       "  '5TbUxGZtwGI']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(['title', 'video_id']).collect()[idx_result].to_dict(as_series=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_response(question, df):\n",
    "\n",
    "    idx_result = returnSearchResults(question, df)\n",
    "    result = df.select(['title', 'video_id']).collect()[idx_result]\n",
    "    \n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
